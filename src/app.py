"""
Interface Streamlit â€” Chat RAG para Documentos Normativos da UNIVASF

Uso:
    streamlit run src/app.py
"""

import sys
from pathlib import Path

# Adiciona o diretÃ³rio raiz ao path
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

import streamlit as st
import logging

from src.retrieval.hybrid_search import HybridSearchEngine, SearchResult
from src.retrieval.reranker import rerank
from src.generation.generator import generate_answer, GenerationResult

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# â”€â”€ ConfiguraÃ§Ã£o da PÃ¡gina â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.set_page_config(
    page_title="RAG UNIVASF â€” Assistente Normativo",
    page_icon="ğŸ“œ",
    layout="wide",
    initial_sidebar_state="expanded",
)

# â”€â”€ CSS Customizado â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)


# â”€â”€ InicializaÃ§Ã£o do Estado â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@st.cache_resource
def load_search_engine():
    """Carrega o motor de busca uma Ãºnica vez."""
    try:
        engine = HybridSearchEngine()
        return engine
    except Exception as e:
        st.error(f"Erro ao carregar motor de busca: {e}")
        st.info("Execute o pipeline ETL primeiro:\n```\npython scripts/run_etl.py\npython scripts/run_indexing.py\n```")
        return None


def initialize_session():
    """Inicializa variÃ¡veis de sessÃ£o."""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "sources" not in st.session_state:
        st.session_state.sources = []


# â”€â”€ Sidebar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def render_sidebar():
    """Renderiza a barra lateral com configuraÃ§Ãµes e info."""
    with st.sidebar:
        st.markdown("## âš™ï¸ ConfiguraÃ§Ãµes")

        filter_revoked = st.checkbox(
            "Filtrar documentos revogados",
            value=True,
            help="Exclui documentos marcados como revogados da busca"
        )

        top_k = st.slider(
            "Documentos finais (pÃ³s-reranking)",
            min_value=1,
            max_value=10,
            value=5,
            help="NÃºmero de documentos enviados ao LLM"
        )

        st.markdown("---")

        st.markdown("## ğŸ“Š InformaÃ§Ãµes")
        engine = load_search_engine()
        if engine:
            st.metric("Chunks Indexados", len(engine.chunks))

            categories = set()
            for chunk in engine.chunks:
                categories.add(chunk.metadata.category)
            st.markdown(f"**Categorias:** {', '.join(sorted(categories))}")

        st.markdown("---")
        st.markdown(
            "### ğŸ“š Sobre\n"
            "Sistema RAG para consulta de documentos normativos da UNIVASF.\n\n"
            "**TCC** â€” GeraÃ§Ã£o Aumentada por RecuperaÃ§Ã£o (RAG) para "
            "Automatizar a Consulta de Documentos Normativos."
        )

        return filter_revoked, top_k


# â”€â”€ Pipeline de Resposta â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_rag_pipeline(
    query: str,
    engine: HybridSearchEngine,
    filter_revoked: bool = True,
    top_k: int = 5,
) -> tuple[GenerationResult, list[SearchResult]]:
    """
    Executa o pipeline RAG completo:
    1. Busca densa HNSW (ChromaDB)
    2. Reranking (cross-encoder)
    3. GeraÃ§Ã£o (LLM)
    """
    # 1. Busca HNSW â€” top-50 candidatos
    with st.spinner("ğŸ” Buscando nos documentos normativos..."):
        candidates = engine.search_hybrid(
            query=query,
            filter_revoked=filter_revoked,
        )

    # 2. Reranking â€” top-5
    with st.spinner("ğŸ“Š Reordenando por relevÃ¢ncia..."):
        top_results = rerank(query, candidates, top_k=top_k)

    # 3. GeraÃ§Ã£o
    with st.spinner("ğŸ’¬ Gerando resposta fundamentada..."):
        result = generate_answer(query, top_results)

    return result, top_results


# â”€â”€ RenderizaÃ§Ã£o de Fontes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _strip_markdown(text: str) -> str:
    """Remove marcadores Markdown e HTML do texto para exibiÃ§Ã£o limpa."""
    import re
    # Remove headers markdown (# ## ###)
    text = re.sub(r"^#{1,6}\s*", "", text, flags=re.MULTILINE)
    # Remove bold/itÃ¡lico (**texto** ou *texto*)
    text = re.sub(r"\*{1,2}(.+?)\*{1,2}", r"\1", text)
    # Remove tags HTML
    text = re.sub(r"<[^>]+>", "", text)
    # Remove linhas horizontais markdown
    text = re.sub(r"^-{3,}$", "", text, flags=re.MULTILINE)
    # Remove espaÃ§os duplicados
    text = re.sub(r"\n{3,}", "\n\n", text)
    return text.strip()


@st.cache_data
def _find_source_pdf(source_name: str) -> Path | None:
    """
    Busca o PDF original correspondente ao nome da fonte.

    Percorre recursivamente regimentos_estatutos_resolucoes/ procurando
    um PDF cujo nome contenha o source_name do chunk.
    """
    from src.config import DOCUMENTS_DIR
    import unicodedata

    def normalize(s: str) -> str:
        """Normaliza string para comparaÃ§Ã£o (remove acentos, lowercase)."""
        s = unicodedata.normalize("NFKD", s)
        s = "".join(c for c in s if not unicodedata.combining(c))
        return s.lower().replace(" ", "").replace("_", "").replace("-", "")

    source_norm = normalize(source_name)

    for pdf_path in DOCUMENTS_DIR.rglob("*.pdf"):
        pdf_norm = normalize(pdf_path.stem)
        if source_norm in pdf_norm or pdf_norm in source_norm:
            return pdf_path

    return None


def render_sources(sources: list[SearchResult]):
    """Renderiza os cartÃµes de fontes consultadas usando componentes nativos."""
    if not sources:
        return

    with st.expander("ğŸ“ Fontes Consultadas", expanded=False):
        for i, result in enumerate(sources, 1):
            meta = result.metadata
            source = meta.get("source", "Desconhecido")
            article = meta.get("article_id", "")
            category = meta.get("category", "")
            hierarchy = meta.get("hierarchy", "")
            score = result.score

            st.markdown(f"**ğŸ“„ {source}** {f'â€” {article}' if article else ''}")

            cols = st.columns([2, 2, 1])
            with cols[0]:
                st.caption(f"Categoria: {category}")
            with cols[1]:
                if hierarchy:
                    st.caption(f"Hierarquia: {hierarchy}")
            with cols[2]:
                st.caption(f"Score: {score:.4f}")

            # BotÃµes: ver trecho + baixar PDF
            btn_cols = st.columns([1, 1, 3])
            with btn_cols[0]:
                with st.popover(f"Ver trecho #{i}"):
                    clean_text = _strip_markdown(result.content[:600])
                    st.text(clean_text + ("..." if len(result.content) > 600 else ""))

            with btn_cols[1]:
                pdf_path = _find_source_pdf(source)
                if pdf_path and pdf_path.exists():
                    with open(pdf_path, "rb") as f:
                        st.download_button(
                            label="â¬‡ï¸ Baixar PDF",
                            data=f,
                            file_name=pdf_path.name,
                            mime="application/pdf",
                            key=f"dl_{i}_{source}",
                        )

            st.divider()


# â”€â”€ Interface Principal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    initialize_session()

    # Header
    st.markdown(
        "<div class='main-header'>"
        "<h1>ğŸ“œ Assistente Normativo UNIVASF</h1>"
        "<p>Consulte estatutos, regimentos e resoluÃ§Ãµes da universidade</p>"
        "</div>",
        unsafe_allow_html=True,
    )

    # Sidebar
    filter_revoked, top_k = render_sidebar()

    # Carrega motor de busca
    engine = load_search_engine()
    if engine is None:
        st.stop()

    # HistÃ³rico de chat
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

            # Mostra fontes e mÃ©tricas para mensagens do assistente
            if msg["role"] == "assistant":
                if "sources" in msg:
                    render_sources(msg["sources"])
                if "metrics" in msg:
                    st.caption(msg["metrics"])

    # Input do usuÃ¡rio
    user_input = st.chat_input(
        "FaÃ§a uma pergunta sobre as normas da UNIVASF..."
    )

    if user_input:
        # Exibe mensagem do usuÃ¡rio
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        # Executa pipeline RAG
        with st.chat_message("assistant"):
            try:
                result, top_results = run_rag_pipeline(
                    query=user_input,
                    engine=engine,
                    filter_revoked=filter_revoked,
                    top_k=top_k,
                )

                # Exibe resposta
                st.markdown(result.answer)

                # Exibe fontes
                render_sources(top_results)

                # MÃ©tricas de uso
                metrics_text = (
                    f"ğŸ”¢ Tokens: {result.prompt_tokens} (prompt) + "
                    f"{result.completion_tokens} (resposta) | "
                    f"ğŸ“„ {len(top_results)} fontes consultadas"
                )
                st.caption(metrics_text)

                # Salva no histÃ³rico (incluindo mÃ©tricas)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": result.answer,
                    "sources": top_results,
                    "metrics": metrics_text,
                })

            except Exception as e:
                st.error(f"Erro ao processar sua pergunta: {e}")
                logger.error(f"Erro no pipeline: {e}", exc_info=True)


if __name__ == "__main__":
    main()
